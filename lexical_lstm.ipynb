{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import paths\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InterviewID</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Interviewer: So how are you doing?|Interviewee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P10</td>\n",
       "      <td>Interviewer: So  how you doing?|Interviewee: G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P11</td>\n",
       "      <td>Interviewer: So  tell me about yourself. |Inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P12</td>\n",
       "      <td>Interviewer: So how are you doing today?|Inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P13</td>\n",
       "      <td>Interviewer: How are you doing today?|Intervie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InterviewID                                         Transcript\n",
       "0          P1  Interviewer: So how are you doing?|Interviewee...\n",
       "1         P10  Interviewer: So  how you doing?|Interviewee: G...\n",
       "2         P11  Interviewer: So  tell me about yourself. |Inte...\n",
       "3         P12  Interviewer: So how are you doing today?|Inter...\n",
       "4         P13  Interviewer: How are you doing today?|Intervie..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_df = pd.read_csv('data/Labels/interview_transcripts_by_turkers.csv', header=None)\n",
    "lexical_df.columns = ['InterviewID', 'Transcript']\n",
    "lexical_df['InterviewID'] = lexical_df['InterviewID'].str.upper()\n",
    "lexical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "interviewee_responses = {}\n",
    "\n",
    "# Iterate through the dataframe rows\n",
    "for index, row in lexical_df.iterrows():\n",
    "    transcript = row['Transcript']\n",
    "    \n",
    "    # Split the transcript into interview segments\n",
    "    segments = transcript.split('|')\n",
    "    \n",
    "    # Extract interviewee responses\n",
    "    interviewee_response = \"\"\n",
    "    for segment in segments:\n",
    "        if 'Interviewee:' in segment:\n",
    "            interviewee_response += segment.replace('Interviewee:', '').strip() + \" \"\n",
    "    \n",
    "    # Append interviewee response to the list\n",
    "    interviewee_responses[row['InterviewID']] = interviewee_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InterviewID</th>\n",
       "      <th>Transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Im pretty good. ok  uhm  so have you looked at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P10</td>\n",
       "      <td>Great  how about you? I'm a little [???] by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P11</td>\n",
       "      <td>Uhh  I’m a junior at MIT  uhh I’m double major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P12</td>\n",
       "      <td>I'm good  how are you? Ok  so  I'm a Junior at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P13</td>\n",
       "      <td>Good. Ok  umm  I'm currently a junior at M.I.T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InterviewID                                         Transcript\n",
       "0          P1  Im pretty good. ok  uhm  so have you looked at...\n",
       "1         P10  Great  how about you? I'm a little [???] by th...\n",
       "2         P11  Uhh  I’m a junior at MIT  uhh I’m double major...\n",
       "3         P12  I'm good  how are you? Ok  so  I'm a Junior at...\n",
       "4         P13  Good. Ok  umm  I'm currently a junior at M.I.T..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interviewee_responses_df = pd.DataFrame.from_dict(interviewee_responses, orient='index')\n",
    "interviewee_responses_df.columns = ['Transcript']\n",
    "interviewee_responses_df.reset_index(level=0, inplace=True)\n",
    "interviewee_responses_df.columns = ['InterviewID', 'Transcript']\n",
    "interviewee_responses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(paths.labels_path)\n",
    "df_labels = df_labels.rename(columns={'Participant': 'InterviewID'})\n",
    "df_labels = df_labels.drop(columns=['Worker'])\n",
    "df_labels = df_labels.groupby('InterviewID').mean().reset_index()\n",
    "df_labels['InterviewID'] = df_labels['InterviewID'].str.upper()\n",
    "\n",
    "medians = df_labels.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InterviewID</th>\n",
       "      <th>StructuredAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InterviewID  StructuredAnswers\n",
       "0          P1               True\n",
       "1         P10              False\n",
       "2         P11               True\n",
       "3         P12              False\n",
       "4         P13               True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify = {}\n",
    "ids = df_labels['InterviewID']\n",
    "for i in ids:\n",
    "    if df_labels[df_labels['InterviewID'] == i]['StructuredAnswers'].values[0] >= medians['StructuredAnswers']:\n",
    "        classify[i] = True\n",
    "    else:\n",
    "        classify[i] = False\n",
    "classify_df = pd.DataFrame.from_dict(classify, orient='index')\n",
    "classify_df.columns = ['StructuredAnswers']\n",
    "classify_df.reset_index(level=0, inplace=True)\n",
    "classify_df.columns = ['InterviewID', 'StructuredAnswers']\n",
    "classify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InterviewID</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>StructuredAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Im pretty good. ok  uhm  so have you looked at...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P10</td>\n",
       "      <td>Great  how about you? I'm a little [???] by th...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P11</td>\n",
       "      <td>Uhh  I’m a junior at MIT  uhh I’m double major...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P12</td>\n",
       "      <td>I'm good  how are you? Ok  so  I'm a Junior at...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P13</td>\n",
       "      <td>Good. Ok  umm  I'm currently a junior at M.I.T...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InterviewID                                         Transcript  \\\n",
       "0          P1  Im pretty good. ok  uhm  so have you looked at...   \n",
       "1         P10  Great  how about you? I'm a little [???] by th...   \n",
       "2         P11  Uhh  I’m a junior at MIT  uhh I’m double major...   \n",
       "3         P12  I'm good  how are you? Ok  so  I'm a Junior at...   \n",
       "4         P13  Good. Ok  umm  I'm currently a junior at M.I.T...   \n",
       "\n",
       "   StructuredAnswers  \n",
       "0               True  \n",
       "1              False  \n",
       "2               True  \n",
       "3              False  \n",
       "4               True  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dataframes\n",
    "df = pd.merge(interviewee_responses_df, classify_df, on='InterviewID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "transcripts = df['Transcript'].values\n",
    "labels = df['StructuredAnswers'].values\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(transcripts)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(transcripts)\n",
    "\n",
    "# Pad sequences for uniform length\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_msg_text = \" \".join(msg for msg in df[df['StructuredAnswers'] == False].Transcript)\n",
    "\n",
    "ham_msg_cloud = WordCloud(width =520, height =260, stopwords = STOPWORDS, max_font_size = 50, background_color = \"black\", colormap = 'Pastel1').generate(ham_msg_text)\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.imshow(ham_msg_cloud, interpolation = 'bilinear')\n",
    "plt.axis('off') # turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 15:31:46.907604: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:512 : INVALID_ARGUMENT: Trying to access resource dense_1/kernel/36 (defined @ /home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n",
      "2023-11-30 15:31:46.907656: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:512 : INVALID_ARGUMENT: Trying to access resource dense_1/bias/37 (defined @ /home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n",
      " Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node Adam/StatefulPartitionedCall_4 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n\n  File \"/tmp/ipykernel_10992/4211684127.py\", line 3, in <module>\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nTrying to access resource dense_1/kernel/36 (defined @ /home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node Adam/StatefulPartitionedCall_4}}]] [Op:__inference_train_function_14345]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/malhaar/cs/mlpr/project/lexical_lstm.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/malhaar/cs/mlpr/project/lexical_lstm.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/cpu:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/malhaar/cs/mlpr/project/lexical_lstm.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/malhaar/cs/mlpr/project/lexical_lstm.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Adam/StatefulPartitionedCall_4 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n\n  File \"/tmp/ipykernel_10992/4211684127.py\", line 3, in <module>\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1253, in _internal_apply_gradients\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n\n  File \"/home/malhaar/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py\", line 1340, in apply_grad_to_update_var\n\nTrying to access resource dense_1/kernel/36 (defined @ /home/malhaar/.local/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py:137) located in device /job:localhost/replica:0/task:0/device:GPU:0 from device /job:localhost/replica:0/task:0/device:CPU:0\n Cf. https://www.tensorflow.org/xla/known_issues#tfvariable_on_a_different_device\n\t [[{{node Adam/StatefulPartitionedCall_4}}]] [Op:__inference_train_function_14345]"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'new_data' is a new set of transcripts\n",
    "new_sequences = tokenizer.texts_to_sequences(new_data)\n",
    "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "predictions = model.predict(new_padded_sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
